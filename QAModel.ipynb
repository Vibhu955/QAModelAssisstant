{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I7zcJexHkpfe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Vibhu\\React js\\collab\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "import re\n",
        "import faiss\n",
        "import hashlib\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HR7kUax9kqan"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   questionID                              questionTitle  \\\n",
            "0           0  Do I have too many issues for counseling?   \n",
            "1           0  Do I have too many issues for counseling?   \n",
            "2           0  Do I have too many issues for counseling?   \n",
            "3           0  Do I have too many issues for counseling?   \n",
            "4           0  Do I have too many issues for counseling?   \n",
            "\n",
            "                                        questionText  \\\n",
            "0  I have so many issues to address. I have a his...   \n",
            "1  I have so many issues to address. I have a his...   \n",
            "2  I have so many issues to address. I have a his...   \n",
            "3  I have so many issues to address. I have a his...   \n",
            "4  I have so many issues to address. I have a his...   \n",
            "\n",
            "                                        questionLink       topic  \\\n",
            "0  https://counselchat.com/questions/do-i-have-to...  depression   \n",
            "1  https://counselchat.com/questions/do-i-have-to...  depression   \n",
            "2  https://counselchat.com/questions/do-i-have-to...  depression   \n",
            "3  https://counselchat.com/questions/do-i-have-to...  depression   \n",
            "4  https://counselchat.com/questions/do-i-have-to...  depression   \n",
            "\n",
            "                                       therapistInfo  \\\n",
            "0  Jennifer MolinariHypnotherapist & Licensed Cou...   \n",
            "1  Jason Lynch, MS, LMHC, LCAC, ADSIndividual & C...   \n",
            "2  Shakeeta TorresFaith Based Mental Health Couns...   \n",
            "3  Noorayne ChevalierMA, RP, CCC, CCAC, LLP (Mich...   \n",
            "4  Toni Teixeira, LCSWYour road to healing begins...   \n",
            "\n",
            "                                        therapistURL  \\\n",
            "0  https://counselchat.com/therapists/jennifer-mo...   \n",
            "1  https://counselchat.com/therapists/jason-lynch...   \n",
            "2  https://counselchat.com/therapists/shakeeta-to...   \n",
            "3  https://counselchat.com/therapists/noorayne-ch...   \n",
            "4  https://counselchat.com/therapists/toni-teixei...   \n",
            "\n",
            "                                          answerText  upvotes  views  \\\n",
            "0  It is very common for people to have multiple ...        3   1971   \n",
            "1  I've never heard of someone having \"too many i...        2    386   \n",
            "2  Absolutely not.  I strongly recommending worki...        2   3071   \n",
            "3  Let me start by saying there are never too man...        2   2643   \n",
            "4  I just want to acknowledge you for the courage...        1    256   \n",
            "\n",
            "                                    combinedQuestion  \n",
            "0  Do I have too many issues for counseling? - I ...  \n",
            "1  Do I have too many issues for counseling? - I ...  \n",
            "2  Do I have too many issues for counseling? - I ...  \n",
            "3  Do I have too many issues for counseling? - I ...  \n",
            "4  Do I have too many issues for counseling? - I ...  \n"
          ]
        }
      ],
      "source": [
        "# === Load and clean dataset ===\n",
        "df = pd.read_csv(\"20220401_counsel_chat.zip\")\n",
        "df.dropna(subset=[\"questionText\", \"questionTitle\", \"answerText\", \"therapistInfo\", \"therapistURL\"], inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df[\"combinedQuestion\"] = df[\"questionTitle\"].str.strip() + \" - \" + df[\"questionText\"].str.strip()\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6D0HpTykstT",
        "outputId": "054785b8-d216-446f-9aab-b4ddc59c4fbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Vibhu\\React js\\collab\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vibhu\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "c:\\Users\\Vibhu\\React js\\collab\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vibhu\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "c:\\Users\\Vibhu\\React js\\collab\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vibhu\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# === Load models ===\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "embed_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\", device=device)\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", device=0 if torch.cuda.is_available() else -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ysxAHK0Sku3F"
      },
      "outputs": [],
      "source": [
        "# === Embedding + FAISS ===\n",
        "EMBED_PATH = \"mpnet_embeddings.pt\"\n",
        "INDEX_PATH = \"faiss_index.index\"\n",
        "summary_cache = {}\n",
        "query_cache = {}\n",
        "\n",
        "if not os.path.exists(EMBED_PATH):\n",
        "    embeddings = embed_model.encode(df[\"combinedQuestion\"].tolist(), convert_to_tensor=True, show_progress_bar=True, normalize_embeddings=True)\n",
        "    torch.save(embeddings, EMBED_PATH)\n",
        "else:\n",
        "    embeddings = torch.load(EMBED_PATH)\n",
        "\n",
        "dimension = embeddings.shape[1]\n",
        "if not os.path.exists(INDEX_PATH):\n",
        "    index = faiss.IndexFlatIP(dimension)\n",
        "    index.add(embeddings.cpu().numpy())\n",
        "    faiss.write_index(index, INDEX_PATH)\n",
        "else:\n",
        "    index = faiss.read_index(INDEX_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oiaXWASNk07v"
      },
      "outputs": [],
      "source": [
        "# === Helpers ===\n",
        "def hash_text(text: str) -> str:\n",
        "    return hashlib.md5(text.encode()).hexdigest()\n",
        "\n",
        "def build_psychologytoday_url(name: str) -> str:\n",
        "    cleaned = re.sub(r'(?<=[a-z0-9])(?=[A-Z])', ' ', name)\n",
        "    cleaned = re.sub(r'[\\d/]+', '', cleaned)\n",
        "    capitalized_words = re.findall(r'\\b[A-Z][a-zA-Z\\-]*\\b', cleaned)\n",
        "    first_two = capitalized_words[:2] if capitalized_words else [\"Therapist\"]\n",
        "    query = '+'.join(first_two)\n",
        "    return f\"https://www.psychologytoday.com/us/therapists?search={query}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OE7AV7eqf_CY"
      },
      "outputs": [],
      "source": [
        "#display ans\n",
        "def format_answer(idx, row, summary):\n",
        "    therapist = row.therapistInfo.strip()\n",
        "    topic = row.topic.strip() if pd.notna(row.topic) else \"Unknown\"\n",
        "    therapist_url = build_psychologytoday_url(therapist)\n",
        "    views = int(row.views) if pd.notna(row.views) else 0\n",
        "    upvotes = int(row.upvotes) if pd.notna(row.upvotes) else 0\n",
        "    answer = row.answerText.strip()\n",
        "\n",
        "    return f\"\"\"\n",
        "💡 *Topic*: `{topic}`\n",
        "\n",
        "### 🔷 Answer {idx + 1}\n",
        "👩‍⚕️ **Therapist**: {therapist}  \n",
        "🔗 [PsychologyToday Profile]({therapist_url})  \n",
        "⚠️ _We link to public therapist listings for convenience. We do not verify or endorse them._\n",
        "\n",
        "#### 📝 Summary:\n",
        "{summary}\n",
        "\n",
        "<details>\n",
        "<summary>📖 Click to view full answer</summary>\n",
        "\n",
        "{answer}\n",
        "\n",
        "</details>\n",
        "\n",
        "👁️ **Views**: {views}\n",
        "👍 **Upvotes**: {upvotes}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5d1AW3pYk7Lr"
      },
      "outputs": [],
      "source": [
        "def summarize(text):\n",
        "    key = hash_text(text)\n",
        "    if key in summary_cache:\n",
        "        return summary_cache[key]\n",
        "    short_text = text[:512] if len(text) > 512 else text\n",
        "    result = summarizer(short_text)[0][\"summary_text\"]\n",
        "    summary_cache[key] = result\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oxi2rHMqggfr"
      },
      "outputs": [],
      "source": [
        "# === Main pipeline ===\n",
        "def process_query(query: str) -> str:\n",
        "    if not query:\n",
        "        return \"⚠️ Please enter a query..!!\"\n",
        "\n",
        "    query_key = hash_text(query)\n",
        "    if query_key in query_cache:\n",
        "        return query_cache[query_key]\n",
        "\n",
        "    query_embedding = embed_model.encode([query], convert_to_tensor=True, normalize_embeddings=True)\n",
        "    D, I = index.search(query_embedding.cpu().numpy(), k=50)\n",
        "    filtered_indices = [i for i, score in zip(I[0], D[0]) if score >= 0.4]\n",
        "\n",
        "    if not filtered_indices:\n",
        "        return \"❌ No relevant answers found.\"\n",
        "\n",
        "    top_df = df.iloc[filtered_indices].copy()\n",
        "    pairs = [[query, f\"{row.combinedQuestion} {row.answerText}\"] for row in top_df.itertuples()]\n",
        "    rerank_scores = reranker.predict(pairs)\n",
        "    top_df[\"rerank_score\"] = rerank_scores\n",
        "    top_df = top_df.sort_values(by=[\"rerank_score\", \"views\", \"upvotes\"], ascending=[False, False, False]).head(3)\n",
        "\n",
        "    summaries, results = [], []\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        sum_futures = [executor.submit(summarize, row.answerText) for row in top_df.itertuples()]\n",
        "        for idx, (row, future) in enumerate(zip(top_df.itertuples(), sum_futures)):\n",
        "            sum_text = future.result()\n",
        "            summaries.append(sum_text)\n",
        "            results.append(format_answer(idx, row, sum_text))\n",
        "\n",
        "    final_summary = summarizer(\" \".join(summaries))[0][\"summary_text\"]\n",
        "    full_output = \"\\n\\n---\\n\\n\".join(results) + f\"\\n\\n---\\n\\n🧠 **Final Summary**:\\n{final_summary}\"\n",
        "    query_cache[query_key] = full_output\n",
        "    return full_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save SentenceTransformer\n",
        "with open(\"embed_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(embed_model, f)\n",
        "\n",
        "# Save CrossEncoder\n",
        "with open(\"reranker.pkl\", \"wb\") as f:\n",
        "    pickle.dump(reranker, f)\n",
        "\n",
        "# Save HuggingFace summarizer pipeline\n",
        "with open(\"summarizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(summarizer, f)\n",
        "\n",
        "# Save FAISS index and DataFrame\n",
        "torch.save(embeddings, \"embeddings.pt\")\n",
        "df.to_pickle(\"df.pkl\")\n",
        "faiss.write_index(index, \"faiss_index.index\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "L66lO31dlCWH",
        "outputId": "05cca632-7c9e-42ce-8fcf-cb95155f67de"
      },
      "outputs": [],
      "source": [
        "# === Launch Gradio App ===\n",
        "gr.Interface(\n",
        "    fn=process_query,\n",
        "    inputs=gr.Textbox(label=\"❓ Ask your mental health question here\", placeholder=\"e.g. How can I deal with anxiety about work?\", lines=2),\n",
        "    outputs=gr.Markdown(label=\"🩺 Top Therapist Answers\"),\n",
        "    title=\"🧘 CounselChat Q&A Assistant\",\n",
        "    description=\"Explain in brief about your problems.\",\n",
        "    allow_flagging=\"never\"\n",
        ").launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
